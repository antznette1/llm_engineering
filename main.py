{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a1ea6a-3790-4e98-82e5-461d4942b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d3fcc2-e8b1-4ea8-8e28-30b7324efedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e7d520-7f47-4583-a4b3-8d8ee46fdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(cv_text, job_desc, voice_style, industry):\n",
    "    keywords = extract_keywords(job_desc)\n",
    "    keyword_text = \", \".join(keywords)\n",
    "    \n",
    "    # Extract company name from job description\n",
    "    company_name = extract_company_name(job_desc)\n",
    "    \n",
    "    voice_instructions = {\n",
    "        \"Formal\": \"Use professional, traditional language with formal tone. Focus on precision, structure, and conventional business terminology. Avoid contractions and casual phrases.\",\n",
    "        \"Confident\": \"Use assertive, results-driven language that emphasizes leadership, achievements, and measurable impact. Lead with action verbs and quantify accomplishments.\",\n",
    "        \"Friendly\": \"Use warm, approachable language while maintaining professionalism. Write conversationally but competently, showing personality alongside qualifications.\"\n",
    "    }\n",
    "    \n",
    "    industry_focus = {\n",
    "        \"Tech\": \"Prioritize technical proficiencies, development methodologies, system architectures, coding languages, and quantifiable project outcomes. Include relevant certifications and tools.\",\n",
    "        \"Marketing\": \"Emphasize campaign performance metrics, audience growth, ROI, brand impact, cross-channel strategies, and creative problem-solving. Include specific platforms and tools used.\",\n",
    "        \"UX\": \"Highlight user research methodologies, design thinking processes, usability testing, prototyping tools, accessibility considerations, and user satisfaction improvements.\",\n",
    "        \"Data\": \"Focus on analytical methodologies, statistical modeling, data visualization, programming languages (SQL, Python, R), database management, and business intelligence impact.\",\n",
    "        \"Finance\": \"Emphasize financial modeling, risk analysis, regulatory compliance, audit experience, and cost optimization. Include relevant certifications (CFA, CPA, etc.).\",\n",
    "        \"Healthcare\": \"Highlight patient outcomes, compliance with healthcare regulations, clinical experience, and healthcare technology proficiency.\",\n",
    "        \"Consulting\": \"Focus on client management, problem-solving methodologies, project delivery, and measurable business impact across industries.\"\n",
    "    }\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are a senior career strategist and ATS optimization expert with 15+ years of experience helping candidates land roles at Fortune 500 companies and top startups.\n",
    "\n",
    "## CONTEXT\n",
    "A job seeker needs their application materials optimized for a specific role. You must create materials that achieve a 90%+ ATS compatibility score while compelling human reviewers to schedule interviews.\n",
    "\n",
    "## COMPANY RESEARCH REQUIREMENT\n",
    "Company: {company_name if company_name else '[Extract from job description]'}\n",
    "Before writing the cover letter, research and incorporate:\n",
    "- Company mission, values, and recent developments\n",
    "- Industry challenges they're facing\n",
    "- Their competitive advantages\n",
    "- Recent news, product launches, or achievements\n",
    "- Leadership team insights (if relevant)\n",
    "\n",
    "## YOUR TASKS\n",
    "\n",
    "### 1. CV OPTIMIZATION & ATS SCORING\n",
    "Rewrite the CV following these requirements:\n",
    "- **ATS Compliance**: Use standard section headers (Summary, Experience, Skills, Education), consistent formatting, and keyword density of 2-3%\n",
    "- **Relevance Matching**: Prioritize experiences that directly match job requirements (aim for 80%+ overlap)\n",
    "- **Impact Quantification**: Include specific metrics, percentages, ROI, and measurable outcomes for every role\n",
    "- **Keyword Integration**: Naturally incorporate 15-20 relevant terms from the job description\n",
    "- **Format Optimization**: Use bullet points, clear hierarchy, standard fonts, and ATS-friendly structure\n",
    "- **Skills Prioritization**: List technical skills in order of job description importance\n",
    "- **Length**: Optimize for 1-2 pages maximum with high information density\n",
    "\n",
    "**ATS OPTIMIZATION CHECKLIST:**\n",
    "✓ Standard section headers used\n",
    "✓ No images, tables, or graphics\n",
    "✓ Consistent date formatting\n",
    "✓ Keywords in context (not listed randomly)\n",
    "✓ Proper contact information formatting\n",
    "✓ Standard file format recommendations\n",
    "\n",
    "### 2. RESEARCH-DRIVEN COVER LETTER\n",
    "Write a compelling cover letter that:\n",
    "- **Company-Specific Opening**: Reference specific company initiatives, values, or recent news\n",
    "- **Problem-Solution Fit**: Identify a key challenge the company faces and position yourself as the solution\n",
    "- **Quantified Value Proposition**: Lead with your most impressive, relevant achievement\n",
    "- **Cultural Alignment**: Show understanding of company culture and values\n",
    "- **Future Impact**: Articulate specific contributions you'll make in first 90 days\n",
    "- **Professional Close**: Clear call-to-action with next steps\n",
    "- **Length**: 250-350 words (3-4 tight paragraphs)\n",
    "\n",
    "### 3. SKILLS GAP ANALYSIS\n",
    "Identify:\n",
    "- Skills mentioned in JD but missing from CV\n",
    "- Transferable skills that could be repositioned\n",
    "- Recommended learning resources for any gaps\n",
    "- Certification suggestions relevant to the role\n",
    "\n",
    "### 4. MULTI-VERSION GENERATION\n",
    "Create optimized versions for:\n",
    "- **ATS Version**: Maximum keyword optimization\n",
    "- **Human Reader Version**: More narrative, engaging flow\n",
    "- **LinkedIn Profile Optimization**: Key phrases for profile updates\n",
    "\n",
    "## STYLE GUIDELINES\n",
    "**Voice**: {voice_style}\n",
    "{voice_instructions.get(voice_style, \"Use professional tone appropriate for the role level.\")}\n",
    "\n",
    "**Industry Focus**: {industry}\n",
    "{industry_focus.get(industry, \"Focus on transferable skills and relevant experience for this industry.\")}\n",
    "\n",
    "## SOURCE MATERIALS\n",
    "\n",
    "### ORIGINAL CV:\n",
    "{cv_text}\n",
    "\n",
    "### TARGET JOB DESCRIPTION:\n",
    "{job_desc}\n",
    "\n",
    "### EXTRACTED KEYWORDS:\n",
    "{keyword_text}\n",
    "\n",
    "---\n",
    "\n",
    "## DELIVERABLES\n",
    "Provide your response in exactly these sections:\n",
    "\n",
    "**[ATS_COMPATIBILITY_SCORE]**\n",
    "Score: X/100\n",
    "Key Improvements Made:\n",
    "- [List 3-5 specific optimizations]\n",
    "\n",
    "**[OPTIMIZED_CV_ATS_VERSION]**\n",
    "[ATS-optimized version with maximum keyword integration]\n",
    "\n",
    "**[OPTIMIZED_CV_HUMAN_VERSION]**\n",
    "[More readable version with engaging narrative flow]\n",
    "\n",
    "**[RESEARCH_DRIVEN_COVER_LETTER]**\n",
    "[Tailored cover letter with specific company research integration]\n",
    "\n",
    "**[SKILLS_GAP_ANALYSIS]**\n",
    "Missing Skills: [List with learning resources]\n",
    "Transferable Skills: [Skills to emphasize more]\n",
    "Certification Recommendations: [If applicable]\n",
    "\n",
    "**[KEYWORD_OPTIMIZATION_REPORT]**\n",
    "Keywords Successfully Integrated: [List with frequency]\n",
    "Keyword Density: X%\n",
    "ATS Keyword Match Rate: X%\n",
    "\n",
    "**[LINKEDIN_PROFILE_UPDATES]**\n",
    "Headline Suggestion: [Optimized headline]\n",
    "Summary Updates: [Key phrases to add]\n",
    "Skills to Add: [Priority order]\n",
    "\n",
    "## QUALITY ASSURANCE CHECKLIST\n",
    "Before finalizing, verify:\n",
    "✓ All content truthful and based on original CV\n",
    "✓ Company research is accurate and recent\n",
    "✓ Keywords flow naturally (no stuffing)\n",
    "✓ Quantifiable results included where possible\n",
    "✓ Industry terminology used appropriately\n",
    "✓ Both CV versions complement cover letter\n",
    "✓ ATS compatibility score justified\n",
    "✓ Skills gaps identified with solutions\n",
    "✓ Ready for immediate application submission\n",
    "\n",
    "## SUCCESS METRICS TO OPTIMIZE FOR:\n",
    "- ATS pass rate: 90%+\n",
    "- Keyword relevance score: 85%+\n",
    "- Human engagement factor: High readability + compelling narrative\n",
    "- Application-to-interview conversion: Target 15-20%\n",
    "\"\"\"\n",
    "\n",
    "def extract_company_name(job_desc):\n",
    "    \"\"\"Extract company name from job description using regex or NLP\"\"\"\n",
    "    # Implementation would go here\n",
    "    # For now, return placeholder\n",
    "    import re\n",
    "    \n",
    "    # Simple regex patterns to find company names\n",
    "    patterns = [\n",
    "        r\"at\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+is|\\s+seeks|\\s+looking|\\.|,)\",\n",
    "        r\"([A-Z][a-zA-Z\\s&]+?)\\s+is\\s+(?:seeking|looking|hiring)\",\n",
    "        r\"Join\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+as|\\s+and)\",\n",
    "        r\"Company:\\s*([A-Z][a-zA-Z\\s&]+?)(?:\\n|$)\",\n",
    "    ]\n",
    "    \n",
    "    matches = []\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, job_desc, re.IGNORECASE)\n",
    "        if match:\n",
    "            matches.append(match.group(1).strip())\n",
    "\n",
    "    return random.choice(matches) if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eced4069-44cc-4ad0-91b0-b5a3406aa909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name(job_desc):\n",
    "    \"\"\"Extract company name from job description using regex or NLP\"\"\"\n",
    "    # Implementation would go here\n",
    "    # For now, return placeholder\n",
    "    import re\n",
    "    \n",
    "    # Simple regex patterns to find company names\n",
    "    patterns = [\n",
    "        r\"at\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+is|\\s+seeks|\\s+looking|\\.|,)\",\n",
    "        r\"([A-Z][a-zA-Z\\s&]+?)\\s+is\\s+(?:seeking|looking|hiring)\",\n",
    "        r\"Join\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+as|\\s+and)\",\n",
    "        r\"Company:\\s*([A-Z][a-zA-Z\\s&]+?)(?:\\n|$)\",\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, job_desc, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d8c75a-1419-4277-9a69-5b34b6ef16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached narwhals-1.47.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached narwhals-1.47.1-py3-none-any.whl (375 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, smmap, narwhals, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 gitdb-4.0.12 gitpython-3.1.44 narwhals-1.47.1 pydeck-0.9.1 smmap-5.0.2 streamlit-1.47.0 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6884d3b-2922-4b7c-95cd-e623fb0c6e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\antho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\antho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "2025-07-20 00:59:02.726 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.726 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.799 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\antho\\anaconda3\\envs\\llms\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-20 00:59:02.799 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.800 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.805 Session state does not function when running a script without `streamlit run`\n",
      "2025-07-20 00:59:02.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.094 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.094 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# requirements.txt\n",
    "\"\"\"\n",
    "openai==1.3.0\n",
    "streamlit==1.28.0\n",
    "python-docx==0.8.11\n",
    "PyPDF2==3.0.1\n",
    "nltk==3.8.1\n",
    "scikit-learn==1.3.0\n",
    "requests==2.31.0\n",
    "beautifulsoup4==4.12.2\n",
    "\"\"\"\n",
    "\n",
    "# main.py\n",
    "import streamlit as st\n",
    "import openai\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import io\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "class CVOptimizer:\n",
    "    def __init__(self, openai_api_key):\n",
    "        self.client = openai.OpenAI(api_key=openai_api_key)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_file):\n",
    "        \"\"\"Extract text from uploaded PDF file\"\"\"\n",
    "        try:\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error reading PDF: {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_text_from_docx(self, docx_file):\n",
    "        \"\"\"Extract text from uploaded DOCX file\"\"\"\n",
    "        try:\n",
    "            doc = Document(docx_file)\n",
    "            text = \"\"\n",
    "            for paragraph in doc.paragraphs:\n",
    "                text += paragraph.text + \"\\n\"\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error reading DOCX: {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_keywords(self, job_desc, max_keywords=20):\n",
    "        \"\"\"Extract keywords from job description using TF-IDF\"\"\"\n",
    "        try:\n",
    "            # Clean and tokenize text\n",
    "            words = word_tokenize(job_desc.lower())\n",
    "            words = [word for word in words if word.isalpha() and word not in self.stop_words and len(word) > 2]\n",
    "            \n",
    "            # Use TF-IDF to find important terms\n",
    "            text_for_tfidf = [' '.join(words)]\n",
    "            vectorizer = TfidfVectorizer(max_features=max_keywords, ngram_range=(1, 2))\n",
    "            \n",
    "            try:\n",
    "                tfidf_matrix = vectorizer.fit_transform(text_for_tfidf)\n",
    "                feature_names = vectorizer.get_feature_names_out()\n",
    "                return list(feature_names)\n",
    "            except:\n",
    "                # Fallback to simple word frequency\n",
    "                from collections import Counter\n",
    "                word_freq = Counter(words)\n",
    "                return [word for word, freq in word_freq.most_common(max_keywords)]\n",
    "                \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error extracting keywords: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_company_name(self, job_desc):\n",
    "        \"\"\"Extract company name from job description using regex\"\"\"\n",
    "        patterns = [\n",
    "            r\"at\\s+([A-Z][a-zA-Z\\s&\\.]+?)(?:\\s+is|\\s+seeks|\\s+looking|\\.|,|\\n)\",\n",
    "            r\"([A-Z][a-zA-Z\\s&\\.]+?)\\s+is\\s+(?:seeking|looking|hiring)\",\n",
    "            r\"Join\\s+([A-Z][a-zA-Z\\s&\\.]+?)(?:\\s+as|\\s+and)\",\n",
    "            r\"Company:\\s*([A-Z][a-zA-Z\\s&\\.]+?)(?:\\n|$)\",\n",
    "            r\"Position:\\s*.+?\\s+at\\s+([A-Z][a-zA-Z\\s&\\.]+?)(?:\\n|$)\",\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, job_desc, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                company = match.group(1).strip()\n",
    "                # Clean up common issues\n",
    "                company = re.sub(r'\\s+', ' ', company)  # Multiple spaces\n",
    "                company = company.rstrip('.,!?')  # Trailing punctuation\n",
    "                if len(company) > 3 and len(company) < 50:  # Reasonable length\n",
    "                    return company\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def generate_prompt(self, cv_text, job_desc, voice_style, industry):\n",
    "        \"\"\"Generate the optimized prompt for LLM\"\"\"\n",
    "        keywords = self.extract_keywords(job_desc)\n",
    "        keyword_text = \", \".join(keywords)\n",
    "        company_name = self.extract_company_name(job_desc)\n",
    "        \n",
    "        voice_instructions = {\n",
    "            \"Formal\": \"Use professional, traditional language with formal tone. Focus on precision, structure, and conventional business terminology. Avoid contractions and casual phrases.\",\n",
    "            \"Confident\": \"Use assertive, results-driven language that emphasizes leadership, achievements, and measurable impact. Lead with action verbs and quantify accomplishments.\",\n",
    "            \"Friendly\": \"Use warm, approachable language while maintaining professionalism. Write conversationally but competently, showing personality alongside qualifications.\"\n",
    "        }\n",
    "        \n",
    "        industry_focus = {\n",
    "            \"Tech\": \"Prioritize technical proficiencies, development methodologies, system architectures, coding languages, and quantifiable project outcomes. Include relevant certifications and tools.\",\n",
    "            \"Marketing\": \"Emphasize campaign performance metrics, audience growth, ROI, brand impact, cross-channel strategies, and creative problem-solving. Include specific platforms and tools used.\",\n",
    "            \"UX\": \"Highlight user research methodologies, design thinking processes, usability testing, prototyping tools, accessibility considerations, and user satisfaction improvements.\",\n",
    "            \"Data\": \"Focus on analytical methodologies, statistical modeling, data visualization, programming languages (SQL, Python, R), database management, and business intelligence impact.\",\n",
    "            \"Finance\": \"Emphasize financial modeling, risk analysis, regulatory compliance, audit experience, and cost optimization. Include relevant certifications (CFA, CPA, etc.).\",\n",
    "            \"Healthcare\": \"Highlight patient outcomes, compliance with healthcare regulations, clinical experience, and healthcare technology proficiency.\",\n",
    "            \"Consulting\": \"Focus on client management, problem-solving methodologies, project delivery, and measurable business impact across industries.\"\n",
    "        }\n",
    "        \n",
    "        return f\"\"\"\n",
    "You are a senior career strategist and ATS optimization expert with 15+ years of experience helping candidates land roles at Fortune 500 companies and top startups.\n",
    "\n",
    "## CONTEXT\n",
    "A job seeker needs their application materials optimized for a specific role. You must create materials that achieve a 90%+ ATS compatibility score while compelling human reviewers to schedule interviews.\n",
    "\n",
    "## COMPANY RESEARCH REQUIREMENT\n",
    "Company: {company_name if company_name else '[Extract from job description]'}\n",
    "Before writing the cover letter, research and incorporate:\n",
    "- Company mission, values, and recent developments\n",
    "- Industry challenges they're facing\n",
    "- Their competitive advantages\n",
    "- Recent news, product launches, or achievements\n",
    "\n",
    "## YOUR TASKS\n",
    "\n",
    "### 1. CV OPTIMIZATION & ATS SCORING\n",
    "Rewrite the CV following these requirements:\n",
    "- **ATS Compliance**: Use standard section headers, consistent formatting, and keyword density of 2-3%\n",
    "- **Relevance Matching**: Prioritize experiences that directly match job requirements (aim for 80%+ overlap)\n",
    "- **Impact Quantification**: Include specific metrics, percentages, ROI, and measurable outcomes for every role\n",
    "- **Keyword Integration**: Naturally incorporate 15-20 relevant terms from the job description\n",
    "- **Format Optimization**: Use bullet points, clear hierarchy, standard fonts, and ATS-friendly structure\n",
    "\n",
    "### 2. RESEARCH-DRIVEN COVER LETTER\n",
    "Write a compelling cover letter that:\n",
    "- **Company-Specific Opening**: Reference specific company initiatives, values, or recent news\n",
    "- **Problem-Solution Fit**: Identify a key challenge the company faces and position yourself as the solution\n",
    "- **Quantified Value Proposition**: Lead with your most impressive, relevant achievement\n",
    "- **Professional Close**: Clear call-to-action with next steps\n",
    "- **Length**: 250-350 words (3-4 tight paragraphs)\n",
    "\n",
    "## STYLE GUIDELINES\n",
    "**Voice**: {voice_style}\n",
    "{voice_instructions.get(voice_style, \"Use professional tone appropriate for the role level.\")}\n",
    "\n",
    "**Industry Focus**: {industry}\n",
    "{industry_focus.get(industry, \"Focus on transferable skills and relevant experience for this industry.\")}\n",
    "\n",
    "## SOURCE MATERIALS\n",
    "\n",
    "### ORIGINAL CV:\n",
    "{cv_text}\n",
    "\n",
    "### TARGET JOB DESCRIPTION:\n",
    "{job_desc}\n",
    "\n",
    "### EXTRACTED KEYWORDS:\n",
    "{keyword_text}\n",
    "\n",
    "---\n",
    "\n",
    "## DELIVERABLES\n",
    "Provide your response in exactly these sections:\n",
    "\n",
    "**[ATS_COMPATIBILITY_SCORE]**\n",
    "Score: X/100\n",
    "Key Improvements Made:\n",
    "- [List 3-5 specific optimizations]\n",
    "\n",
    "**[OPTIMIZED_CV]**\n",
    "[Your rewritten CV here - use clear formatting with consistent bullet points]\n",
    "\n",
    "**[COVER_LETTER]**\n",
    "[Your tailored cover letter with specific company research integration]\n",
    "\n",
    "**[KEYWORD_OPTIMIZATION_REPORT]**\n",
    "Keywords Successfully Integrated: [List with frequency]\n",
    "Keyword Density: X%\n",
    "ATS Keyword Match Rate: X%\n",
    "\n",
    "**[SKILLS_GAP_ANALYSIS]**\n",
    "Missing Skills: [List with learning resources]\n",
    "Transferable Skills: [Skills to emphasize more]\n",
    "Certification Recommendations: [If applicable]\n",
    "\n",
    "## QUALITY ASSURANCE CHECKLIST\n",
    "Before finalizing, verify:\n",
    "✓ All content truthful and based on original CV\n",
    "✓ Company research is accurate and recent\n",
    "✓ Keywords flow naturally (no stuffing)\n",
    "✓ Quantifiable results included where possible\n",
    "✓ Industry terminology used appropriately\n",
    "✓ ATS compatibility score justified\n",
    "\"\"\"\n",
    "\n",
    "    def optimize_cv(self, cv_text, job_desc, voice_style, industry):\n",
    "        \"\"\"Send prompt to OpenAI and get optimized CV\"\"\"\n",
    "        try:\n",
    "            prompt = self.generate_prompt(cv_text, job_desc, voice_style, industry)\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4\",  # or \"gpt-3.5-turbo\" for lower cost\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert career strategist and ATS optimization specialist.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=3000,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error calling OpenAI API: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"AI CV Optimizer\",\n",
    "        page_icon=\"📄\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "    \n",
    "    st.title(\"🚀 AI-Powered CV & Cover Letter Optimizer\")\n",
    "    st.markdown(\"Transform your CV into an ATS-friendly, interview-winning document!\")\n",
    "    \n",
    "    # Sidebar for configuration\n",
    "    with st.sidebar:\n",
    "        st.header(\"⚙️ Configuration\")\n",
    "        \n",
    "        # OpenAI API Key\n",
    "        api_key = st.text_input(\"OpenAI API Key\", type=\"password\", help=\"Get your API key from https://platform.openai.com/api-keys\")\n",
    "        \n",
    "        if not api_key:\n",
    "            st.warning(\"Please enter your OpenAI API key to continue.\")\n",
    "            st.stop()\n",
    "        \n",
    "        # Voice style selection\n",
    "        voice_style = st.selectbox(\n",
    "            \"Voice Style\",\n",
    "            [\"Confident\", \"Formal\", \"Friendly\"],\n",
    "            help=\"Choose the tone for your application materials\"\n",
    "        )\n",
    "        \n",
    "        # Industry selection\n",
    "        industry = st.selectbox(\n",
    "            \"Industry\",\n",
    "            [\"Data\", \"Tech\", \"Marketing\", \"UX\", \"Finance\", \"Healthcare\", \"Consulting\"],\n",
    "            help=\"Select your target industry for optimized content\"\n",
    "        )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = CVOptimizer(api_key)\n",
    "    \n",
    "    # Main content area\n",
    "    col1, col2 = st.columns([1, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.header(\"📄 Upload Your CV\")\n",
    "        \n",
    "        # CV upload\n",
    "        cv_file = st.file_uploader(\n",
    "            \"Choose your CV file\",\n",
    "            type=['pdf', 'docx', 'txt'],\n",
    "            help=\"Upload your current CV in PDF, DOCX, or TXT format\"\n",
    "        )\n",
    "        \n",
    "        cv_text = \"\"\n",
    "        if cv_file is not None:\n",
    "            if cv_file.type == \"application/pdf\":\n",
    "                cv_text = optimizer.extract_text_from_pdf(cv_file)\n",
    "            elif cv_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "                cv_text = optimizer.extract_text_from_docx(cv_file)\n",
    "            else:  # txt file\n",
    "                cv_text = str(cv_file.read(), \"utf-8\")\n",
    "            \n",
    "            st.success(f\"✅ CV uploaded successfully! ({len(cv_text)} characters)\")\n",
    "            \n",
    "            # Show preview\n",
    "            with st.expander(\"📖 CV Preview\"):\n",
    "                st.text_area(\"Current CV Content\", cv_text, height=200, disabled=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.header(\"💼 Job Description\")\n",
    "        \n",
    "        job_desc = st.text_area(\n",
    "            \"Paste the job description here\",\n",
    "            height=300,\n",
    "            help=\"Copy and paste the full job description from the job posting\"\n",
    "        )\n",
    "        \n",
    "        if job_desc:\n",
    "            # Extract and show company name\n",
    "            company_name = optimizer.extract_company_name(job_desc)\n",
    "            if company_name:\n",
    "                st.info(f\"🏢 Detected Company: **{company_name}**\")\n",
    "            \n",
    "            # Extract and show keywords\n",
    "            keywords = optimizer.extract_keywords(job_desc)\n",
    "            if keywords:\n",
    "                with st.expander(\"🎯 Extracted Keywords\"):\n",
    "                    st.write(\", \".join(keywords[:10]) + \"...\" if len(keywords) > 10 else \", \".join(keywords))\n",
    "    \n",
    "    # Optimization button\n",
    "    if st.button(\"🚀 Optimize CV & Generate Cover Letter\", type=\"primary\"):\n",
    "        if not cv_text:\n",
    "            st.error(\"Please upload your CV first!\")\n",
    "        elif not job_desc:\n",
    "            st.error(\"Please enter the job description!\")\n",
    "        else:\n",
    "            with st.spinner(\"🤖 AI is optimizing your application materials...\"):\n",
    "                result = optimizer.optimize_cv(cv_text, job_desc, voice_style, industry)\n",
    "                \n",
    "                if result:\n",
    "                    st.success(\"✅ Optimization completed!\")\n",
    "                    \n",
    "                    # Display results in tabs\n",
    "                    tabs = st.tabs([\"📊 ATS Score\", \"📄 Optimized CV\", \"💌 Cover Letter\", \"📈 Analytics\", \"🎯 Skills Gap\"])\n",
    "                    \n",
    "                    # Parse the result sections\n",
    "                    sections = {}\n",
    "                    current_section = None\n",
    "                    current_content = []\n",
    "                    \n",
    "                    for line in result.split('\\n'):\n",
    "                        if line.startswith('**[') and line.endswith(']**'):\n",
    "                            if current_section:\n",
    "                                sections[current_section] = '\\n'.join(current_content)\n",
    "                            current_section = line.strip('**[]')\n",
    "                            current_content = []\n",
    "                        else:\n",
    "                            current_content.append(line)\n",
    "                    \n",
    "                    if current_section:\n",
    "                        sections[current_section] = '\\n'.join(current_content)\n",
    "                    \n",
    "                    # Display in tabs\n",
    "                    with tabs[0]:\n",
    "                        if 'ATS_COMPATIBILITY_SCORE' in sections:\n",
    "                            st.markdown(\"### 🎯 ATS Compatibility Analysis\")\n",
    "                            st.markdown(sections['ATS_COMPATIBILITY_SCORE'])\n",
    "                    \n",
    "                    with tabs[1]:\n",
    "                        if 'OPTIMIZED_CV' in sections:\n",
    "                            st.markdown(\"### 📄 Your Optimized CV\")\n",
    "                            st.markdown(sections['OPTIMIZED_CV'])\n",
    "                            \n",
    "                            # Download button\n",
    "                            st.download_button(\n",
    "                                label=\"📥 Download Optimized CV\",\n",
    "                                data=sections['OPTIMIZED_CV'],\n",
    "                                file_name=\"optimized_cv.txt\",\n",
    "                                mime=\"text/plain\"\n",
    "                            )\n",
    "                    \n",
    "                    with tabs[2]:\n",
    "                        if 'COVER_LETTER' in sections:\n",
    "                            st.markdown(\"### 💌 Your Tailored Cover Letter\")\n",
    "                            st.markdown(sections['COVER_LETTER'])\n",
    "                            \n",
    "                            # Download button\n",
    "                            st.download_button(\n",
    "                                label=\"📥 Download Cover Letter\",\n",
    "                                data=sections['COVER_LETTER'],\n",
    "                                file_name=\"cover_letter.txt\",\n",
    "                                mime=\"text/plain\"\n",
    "                            )\n",
    "                    \n",
    "                    with tabs[3]:\n",
    "                        if 'KEYWORD_OPTIMIZATION_REPORT' in sections:\n",
    "                            st.markdown(\"### 📈 Keyword Optimization Report\")\n",
    "                            st.markdown(sections['KEYWORD_OPTIMIZATION_REPORT'])\n",
    "                    \n",
    "                    with tabs[4]:\n",
    "                        if 'SKILLS_GAP_ANALYSIS' in sections:\n",
    "                            st.markdown(\"### 🎯 Skills Gap Analysis\")\n",
    "                            st.markdown(sections['SKILLS_GAP_ANALYSIS'])\n",
    "                \n",
    "                else:\n",
    "                    st.error(\"Failed to optimize CV. Please check your API key and try again.\")\n",
    "\n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"💡 **Pro Tip**: Always review and customize the generated content before applying!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb297bc9-f22e-4e5c-8af6-c105cc9b52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: openai in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (1.57.0)\n",
      "Requirement already satisfied: requests in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: click in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn openai requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad85f19-4a69-44c6-ac80-55b87374d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c297a0f1-3e46-408d-9c61-f677c0811eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docxNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lxml (from docx)\n",
      "  Downloading lxml-6.0.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: Pillow>=2.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from docx) (11.0.0)\n",
      "Downloading lxml-6.0.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 40.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: docx\n",
      "  Building wheel for docx (setup.py): started\n",
      "  Building wheel for docx (setup.py): finished with status 'done'\n",
      "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53899 sha256=53f313ca1250c8ee3b3d46ea6c7acab17185875715a4901c5a423205097f73a2\n",
      "  Stored in directory: c:\\users\\antho\\appdata\\local\\pip\\cache\\wheels\\c1\\3e\\c3\\e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
      "Successfully built docx\n",
      "Installing collected packages: lxml, docx\n",
      "Successfully installed docx-0.2.4 lxml-6.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178cfc5e-8300-4df9-8941-e536092c31e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (1.57.0)\n",
      "Requirement already satisfied: requests in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f629fed-3e19-4a36-8cc7-d3ed0ce61b56",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3241024564.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install requests\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd1f5fca-fa02-492a-841c-cc91e8ac6031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17f4faa-0237-4717-9971-b0f917e47043",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3987540286.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip uninstall docx\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Uninstall the conflicting package\n",
    "pip uninstall docx\n",
    "\n",
    "# Step 2: Uninstall python-docx\n",
    "pip uninstall python-docx\n",
    "\n",
    "# Step 3: Reinstall the correct python-docx package\n",
    "pip install python-docx\n",
    "\n",
    "# Step 4: Verify it works\n",
    "python -c \"from docx import Document; print('✅ python-docx working!')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117b070c-2290-41ef-9532-af1a03f65385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c878b41c-a4b5-479a-9672-876a2a61aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from python-docx) (6.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "af792e8d-3cd8-46cb-93df-215c032f37ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
