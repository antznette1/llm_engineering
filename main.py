{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a1ea6a-3790-4e98-82e5-461d4942b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d3fcc2-e8b1-4ea8-8e28-30b7324efedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e7d520-7f47-4583-a4b3-8d8ee46fdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(cv_text, job_desc, voice_style, industry):\n",
    "    keywords = extract_keywords(job_desc)\n",
    "    keyword_text = \", \".join(keywords)\n",
    "    \n",
    "    # Extract company name from job description\n",
    "    company_name = extract_company_name(job_desc)\n",
    "    \n",
    "    voice_instructions = {\n",
    "        \"Formal\": \"Use professional, traditional language with formal tone. Focus on precision, structure, and conventional business terminology. Avoid contractions and casual phrases.\",\n",
    "        \"Confident\": \"Use assertive, results-driven language that emphasizes leadership, achievements, and measurable impact. Lead with action verbs and quantify accomplishments.\",\n",
    "        \"Friendly\": \"Use warm, approachable language while maintaining professionalism. Write conversationally but competently, showing personality alongside qualifications.\"\n",
    "    }\n",
    "    \n",
    "    industry_focus = {\n",
    "        \"Tech\": \"Prioritize technical proficiencies, development methodologies, system architectures, coding languages, and quantifiable project outcomes. Include relevant certifications and tools.\",\n",
    "        \"Marketing\": \"Emphasize campaign performance metrics, audience growth, ROI, brand impact, cross-channel strategies, and creative problem-solving. Include specific platforms and tools used.\",\n",
    "        \"UX\": \"Highlight user research methodologies, design thinking processes, usability testing, prototyping tools, accessibility considerations, and user satisfaction improvements.\",\n",
    "        \"Data\": \"Focus on analytical methodologies, statistical modeling, data visualization, programming languages (SQL, Python, R), database management, and business intelligence impact.\",\n",
    "        \"Finance\": \"Emphasize financial modeling, risk analysis, regulatory compliance, audit experience, and cost optimization. Include relevant certifications (CFA, CPA, etc.).\",\n",
    "        \"Healthcare\": \"Highlight patient outcomes, compliance with healthcare regulations, clinical experience, and healthcare technology proficiency.\",\n",
    "        \"Consulting\": \"Focus on client management, problem-solving methodologies, project delivery, and measurable business impact across industries.\"\n",
    "    }\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are a senior career strategist and ATS optimization expert with 15+ years of experience helping candidates land roles at Fortune 500 companies and top startups.\n",
    "\n",
    "## CONTEXT\n",
    "A job seeker needs their application materials optimized for a specific role. You must create materials that achieve a 90%+ ATS compatibility score while compelling human reviewers to schedule interviews.\n",
    "\n",
    "## COMPANY RESEARCH REQUIREMENT\n",
    "Company: {company_name if company_name else '[Extract from job description]'}\n",
    "Before writing the cover letter, research and incorporate:\n",
    "- Company mission, values, and recent developments\n",
    "- Industry challenges they're facing\n",
    "- Their competitive advantages\n",
    "- Recent news, product launches, or achievements\n",
    "- Leadership team insights (if relevant)\n",
    "\n",
    "## YOUR TASKS\n",
    "\n",
    "### 1. CV OPTIMIZATION & ATS SCORING\n",
    "Rewrite the CV following these requirements:\n",
    "- **ATS Compliance**: Use standard section headers (Summary, Experience, Skills, Education), consistent formatting, and keyword density of 2-3%\n",
    "- **Relevance Matching**: Prioritize experiences that directly match job requirements (aim for 80%+ overlap)\n",
    "- **Impact Quantification**: Include specific metrics, percentages, ROI, and measurable outcomes for every role\n",
    "- **Keyword Integration**: Naturally incorporate 15-20 relevant terms from the job description\n",
    "- **Format Optimization**: Use bullet points, clear hierarchy, standard fonts, and ATS-friendly structure\n",
    "- **Skills Prioritization**: List technical skills in order of job description importance\n",
    "- **Length**: Optimize for 1-2 pages maximum with high information density\n",
    "\n",
    "**ATS OPTIMIZATION CHECKLIST:**\n",
    "âœ“ Standard section headers used\n",
    "âœ“ No images, tables, or graphics\n",
    "âœ“ Consistent date formatting\n",
    "âœ“ Keywords in context (not listed randomly)\n",
    "âœ“ Proper contact information formatting\n",
    "âœ“ Standard file format recommendations\n",
    "\n",
    "### 2. RESEARCH-DRIVEN COVER LETTER\n",
    "Write a compelling cover letter that:\n",
    "- **Company-Specific Opening**: Reference specific company initiatives, values, or recent news\n",
    "- **Problem-Solution Fit**: Identify a key challenge the company faces and position yourself as the solution\n",
    "- **Quantified Value Proposition**: Lead with your most impressive, relevant achievement\n",
    "- **Cultural Alignment**: Show understanding of company culture and values\n",
    "- **Future Impact**: Articulate specific contributions you'll make in first 90 days\n",
    "- **Professional Close**: Clear call-to-action with next steps\n",
    "- **Length**: 250-350 words (3-4 tight paragraphs)\n",
    "\n",
    "### 3. SKILLS GAP ANALYSIS\n",
    "Identify:\n",
    "- Skills mentioned in JD but missing from CV\n",
    "- Transferable skills that could be repositioned\n",
    "- Recommended learning resources for any gaps\n",
    "- Certification suggestions relevant to the role\n",
    "\n",
    "### 4. MULTI-VERSION GENERATION\n",
    "Create optimized versions for:\n",
    "- **ATS Version**: Maximum keyword optimization\n",
    "- **Human Reader Version**: More narrative, engaging flow\n",
    "- **LinkedIn Profile Optimization**: Key phrases for profile updates\n",
    "\n",
    "## STYLE GUIDELINES\n",
    "**Voice**: {voice_style}\n",
    "{voice_instructions.get(voice_style, \"Use professional tone appropriate for the role level.\")}\n",
    "\n",
    "**Industry Focus**: {industry}\n",
    "{industry_focus.get(industry, \"Focus on transferable skills and relevant experience for this industry.\")}\n",
    "\n",
    "## SOURCE MATERIALS\n",
    "\n",
    "### ORIGINAL CV:\n",
    "{cv_text}\n",
    "\n",
    "### TARGET JOB DESCRIPTION:\n",
    "{job_desc}\n",
    "\n",
    "### EXTRACTED KEYWORDS:\n",
    "{keyword_text}\n",
    "\n",
    "---\n",
    "\n",
    "## DELIVERABLES\n",
    "Provide your response in exactly these sections:\n",
    "\n",
    "**[ATS_COMPATIBILITY_SCORE]**\n",
    "Score: X/100\n",
    "Key Improvements Made:\n",
    "- [List 3-5 specific optimizations]\n",
    "\n",
    "**[OPTIMIZED_CV_ATS_VERSION]**\n",
    "[ATS-optimized version with maximum keyword integration]\n",
    "\n",
    "**[OPTIMIZED_CV_HUMAN_VERSION]**\n",
    "[More readable version with engaging narrative flow]\n",
    "\n",
    "**[RESEARCH_DRIVEN_COVER_LETTER]**\n",
    "[Tailored cover letter with specific company research integration]\n",
    "\n",
    "**[SKILLS_GAP_ANALYSIS]**\n",
    "Missing Skills: [List with learning resources]\n",
    "Transferable Skills: [Skills to emphasize more]\n",
    "Certification Recommendations: [If applicable]\n",
    "\n",
    "**[KEYWORD_OPTIMIZATION_REPORT]**\n",
    "Keywords Successfully Integrated: [List with frequency]\n",
    "Keyword Density: X%\n",
    "ATS Keyword Match Rate: X%\n",
    "\n",
    "**[LINKEDIN_PROFILE_UPDATES]**\n",
    "Headline Suggestion: [Optimized headline]\n",
    "Summary Updates: [Key phrases to add]\n",
    "Skills to Add: [Priority order]\n",
    "\n",
    "## QUALITY ASSURANCE CHECKLIST\n",
    "Before finalizing, verify:\n",
    "âœ“ All content truthful and based on original CV\n",
    "âœ“ Company research is accurate and recent\n",
    "âœ“ Keywords flow naturally (no stuffing)\n",
    "âœ“ Quantifiable results included where possible\n",
    "âœ“ Industry terminology used appropriately\n",
    "âœ“ Both CV versions complement cover letter\n",
    "âœ“ ATS compatibility score justified\n",
    "âœ“ Skills gaps identified with solutions\n",
    "âœ“ Ready for immediate application submission\n",
    "\n",
    "## SUCCESS METRICS TO OPTIMIZE FOR:\n",
    "- ATS pass rate: 90%+\n",
    "- Keyword relevance score: 85%+\n",
    "- Human engagement factor: High readability + compelling narrative\n",
    "- Application-to-interview conversion: Target 15-20%\n",
    "\"\"\"\n",
    "\n",
    "def extract_company_name(job_desc):\n",
    "    \"\"\"Extract company name from job description using regex or NLP\"\"\"\n",
    "    # Implementation would go here\n",
    "    # For now, return placeholder\n",
    "    import re\n",
    "    \n",
    "    # Simple regex patterns to find company names\n",
    "    patterns = [\n",
    "        r\"at\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+is|\\s+seeks|\\s+looking|\\.|,)\",\n",
    "        r\"([A-Z][a-zA-Z\\s&]+?)\\s+is\\s+(?:seeking|looking|hiring)\",\n",
    "        r\"Join\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+as|\\s+and)\",\n",
    "        r\"Company:\\s*([A-Z][a-zA-Z\\s&]+?)(?:\\n|$)\",\n",
    "    ]\n",
    "    \n",
    "    matches = []\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, job_desc, re.IGNORECASE)\n",
    "        if match:\n",
    "            matches.append(match.group(1).strip())\n",
    "\n",
    "    return random.choice(matches) if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eced4069-44cc-4ad0-91b0-b5a3406aa909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name(job_desc):\n",
    "    \"\"\"Extract company name from job description using regex or NLP\"\"\"\n",
    "    # Implementation would go here\n",
    "    # For now, return placeholder\n",
    "    import re\n",
    "    \n",
    "    # Simple regex patterns to find company names\n",
    "    patterns = [\n",
    "        r\"at\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+is|\\s+seeks|\\s+looking|\\.|,)\",\n",
    "        r\"([A-Z][a-zA-Z\\s&]+?)\\s+is\\s+(?:seeking|looking|hiring)\",\n",
    "        r\"Join\\s+([A-Z][a-zA-Z\\s&]+?)(?:\\s+as|\\s+and)\",\n",
    "        r\"Company:\\s*([A-Z][a-zA-Z\\s&]+?)(?:\\n|$)\",\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, job_desc, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d8c75a-1419-4277-9a69-5b34b6ef16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached narwhals-1.47.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached narwhals-1.47.1-py3-none-any.whl (375 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, smmap, narwhals, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 gitdb-4.0.12 gitpython-3.1.44 narwhals-1.47.1 pydeck-0.9.1 smmap-5.0.2 streamlit-1.47.0 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6884d3b-2922-4b7c-95cd-e623fb0c6e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\antho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\antho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "2025-07-20 00:59:02.726 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.726 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.799 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\antho\\anaconda3\\envs\\llms\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-20 00:59:02.799 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.800 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.805 Session state does not function when running a script without `streamlit run`\n",
      "2025-07-20 00:59:02.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:02.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.093 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.094 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.094 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.095 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.096 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.102 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-20 00:59:03.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# requirements.txt\n",
    "\"\"\"\n",
    "openai==1.3.0\n",
    "streamlit==1.28.0\n",
    "python-docx==0.8.11\n",
    "PyPDF2==3.0.1\n",
    "nltk==3.8.1\n",
    "scikit-learn==1.3.0\n",
    "requests==2.31.0\n",
    "beautifulsoup4==4.12.2\n",
    "\"\"\"\n",
    "\n",
    "# main.py\n",
    "import streamlit as st\n",
    "import openai\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import io\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "class CVOptimizer:\n",
    "    def __init__(self, openai_api_key):\n",
    "        self.client = openai.OpenAI(api_key=openai_api_key)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_file):\n",
    "        \"\"\"Extract text from uploaded PDF file\"\"\"\n",
    "        try:\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error reading PDF: {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_text_from_docx(self, docx_file):\n",
    "        \"\"\"Extract text from uploaded DOCX file\"\"\"\n",
    "        try:\n",
    "            doc = Document(docx_file)\n",
    "            text = \"\"\n",
    "            for paragraph in doc.paragraphs:\n",
    "                text += paragraph.text + \"\\n\"\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error reading DOCX: {str(e)}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_keywords(self, job_desc, max_keywords=20):\n",
    "        \"\"\"Extract keywords from job description using TF-IDF\"\"\"\n",
    "        try:\n",
    "            # Clean and tokenize text\n",
    "            words = word_tokenize(job_desc.lower())\n",
    "            words = [word for word in words if word.isalpha() and word not in self.stop_words and len(word) > 2]\n",
    "            \n",
    "            # Use TF-IDF to find important terms\n",
    "            text_for_tfidf = [' '.join(words)]\n",
    "            vectorizer = TfidfVectorizer(max_features=max_keywords, ngram_range=(1, 2))\n",
    "            \n",
    "            try:\n",
    "                tfidf_matrix = vectorizer.fit_transform(text_for_tfidf)\n",
    "                feature_names = vectorizer.get_feature_names_out()\n",
    "                return list(feature_names)\n",
    "            except:\n",
    "                # Fallback to simple word frequency\n",
    "                from collections import Counter\n",
    "                word_freq = Counter(words)\n",
    "                return [word for word, freq in word_freq.most_common(max_keywords)]\n",
    "                \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error extracting keywords: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_company_name(self, job_desc):\n",
    "        \"\"\"Extract company name from job description using regex\"\"\"\n",
    "        patterns = [\n",
    "            r\"at\\s+([A-Z][a-zA-Z\\s&\\.]+?)(?:\\s+is|\\s+seeks|\\s+looking|\\.|,|\\n)\",\n",
    "            r\"([A-Z][a-zA-Z\\s&\\.]+?)\\s+is\\s+(?:seeking|looking|hiring)\",\n",
    "            r\"Join\\s+([A-Z][a-zA-Z\\s&\\.]+?)(?:\\s+as|\\s+and)\",\n",
    "            r\"Company:\\s*([A-Z][a-zA-Z\\s&\\.]+?)(?:\\n|$)\",\n",
    "            r\"Position:\\s*.+?\\s+at\\s+([A-Z][a-zA-Z\\s&\\.]+?)(?:\\n|$)\",\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, job_desc, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                company = match.group(1).strip()\n",
    "                # Clean up common issues\n",
    "                company = re.sub(r'\\s+', ' ', company)  # Multiple spaces\n",
    "                company = company.rstrip('.,!?')  # Trailing punctuation\n",
    "                if len(company) > 3 and len(company) < 50:  # Reasonable length\n",
    "                    return company\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def generate_prompt(self, cv_text, job_desc, voice_style, industry):\n",
    "        \"\"\"Generate the optimized prompt for LLM\"\"\"\n",
    "        keywords = self.extract_keywords(job_desc)\n",
    "        keyword_text = \", \".join(keywords)\n",
    "        company_name = self.extract_company_name(job_desc)\n",
    "        \n",
    "        voice_instructions = {\n",
    "            \"Formal\": \"Use professional, traditional language with formal tone. Focus on precision, structure, and conventional business terminology. Avoid contractions and casual phrases.\",\n",
    "            \"Confident\": \"Use assertive, results-driven language that emphasizes leadership, achievements, and measurable impact. Lead with action verbs and quantify accomplishments.\",\n",
    "            \"Friendly\": \"Use warm, approachable language while maintaining professionalism. Write conversationally but competently, showing personality alongside qualifications.\"\n",
    "        }\n",
    "        \n",
    "        industry_focus = {\n",
    "            \"Tech\": \"Prioritize technical proficiencies, development methodologies, system architectures, coding languages, and quantifiable project outcomes. Include relevant certifications and tools.\",\n",
    "            \"Marketing\": \"Emphasize campaign performance metrics, audience growth, ROI, brand impact, cross-channel strategies, and creative problem-solving. Include specific platforms and tools used.\",\n",
    "            \"UX\": \"Highlight user research methodologies, design thinking processes, usability testing, prototyping tools, accessibility considerations, and user satisfaction improvements.\",\n",
    "            \"Data\": \"Focus on analytical methodologies, statistical modeling, data visualization, programming languages (SQL, Python, R), database management, and business intelligence impact.\",\n",
    "            \"Finance\": \"Emphasize financial modeling, risk analysis, regulatory compliance, audit experience, and cost optimization. Include relevant certifications (CFA, CPA, etc.).\",\n",
    "            \"Healthcare\": \"Highlight patient outcomes, compliance with healthcare regulations, clinical experience, and healthcare technology proficiency.\",\n",
    "            \"Consulting\": \"Focus on client management, problem-solving methodologies, project delivery, and measurable business impact across industries.\"\n",
    "        }\n",
    "        \n",
    "        return f\"\"\"\n",
    "You are a senior career strategist and ATS optimization expert with 15+ years of experience helping candidates land roles at Fortune 500 companies and top startups.\n",
    "\n",
    "## CONTEXT\n",
    "A job seeker needs their application materials optimized for a specific role. You must create materials that achieve a 90%+ ATS compatibility score while compelling human reviewers to schedule interviews.\n",
    "\n",
    "## COMPANY RESEARCH REQUIREMENT\n",
    "Company: {company_name if company_name else '[Extract from job description]'}\n",
    "Before writing the cover letter, research and incorporate:\n",
    "- Company mission, values, and recent developments\n",
    "- Industry challenges they're facing\n",
    "- Their competitive advantages\n",
    "- Recent news, product launches, or achievements\n",
    "\n",
    "## YOUR TASKS\n",
    "\n",
    "### 1. CV OPTIMIZATION & ATS SCORING\n",
    "Rewrite the CV following these requirements:\n",
    "- **ATS Compliance**: Use standard section headers, consistent formatting, and keyword density of 2-3%\n",
    "- **Relevance Matching**: Prioritize experiences that directly match job requirements (aim for 80%+ overlap)\n",
    "- **Impact Quantification**: Include specific metrics, percentages, ROI, and measurable outcomes for every role\n",
    "- **Keyword Integration**: Naturally incorporate 15-20 relevant terms from the job description\n",
    "- **Format Optimization**: Use bullet points, clear hierarchy, standard fonts, and ATS-friendly structure\n",
    "\n",
    "### 2. RESEARCH-DRIVEN COVER LETTER\n",
    "Write a compelling cover letter that:\n",
    "- **Company-Specific Opening**: Reference specific company initiatives, values, or recent news\n",
    "- **Problem-Solution Fit**: Identify a key challenge the company faces and position yourself as the solution\n",
    "- **Quantified Value Proposition**: Lead with your most impressive, relevant achievement\n",
    "- **Professional Close**: Clear call-to-action with next steps\n",
    "- **Length**: 250-350 words (3-4 tight paragraphs)\n",
    "\n",
    "## STYLE GUIDELINES\n",
    "**Voice**: {voice_style}\n",
    "{voice_instructions.get(voice_style, \"Use professional tone appropriate for the role level.\")}\n",
    "\n",
    "**Industry Focus**: {industry}\n",
    "{industry_focus.get(industry, \"Focus on transferable skills and relevant experience for this industry.\")}\n",
    "\n",
    "## SOURCE MATERIALS\n",
    "\n",
    "### ORIGINAL CV:\n",
    "{cv_text}\n",
    "\n",
    "### TARGET JOB DESCRIPTION:\n",
    "{job_desc}\n",
    "\n",
    "### EXTRACTED KEYWORDS:\n",
    "{keyword_text}\n",
    "\n",
    "---\n",
    "\n",
    "## DELIVERABLES\n",
    "Provide your response in exactly these sections:\n",
    "\n",
    "**[ATS_COMPATIBILITY_SCORE]**\n",
    "Score: X/100\n",
    "Key Improvements Made:\n",
    "- [List 3-5 specific optimizations]\n",
    "\n",
    "**[OPTIMIZED_CV]**\n",
    "[Your rewritten CV here - use clear formatting with consistent bullet points]\n",
    "\n",
    "**[COVER_LETTER]**\n",
    "[Your tailored cover letter with specific company research integration]\n",
    "\n",
    "**[KEYWORD_OPTIMIZATION_REPORT]**\n",
    "Keywords Successfully Integrated: [List with frequency]\n",
    "Keyword Density: X%\n",
    "ATS Keyword Match Rate: X%\n",
    "\n",
    "**[SKILLS_GAP_ANALYSIS]**\n",
    "Missing Skills: [List with learning resources]\n",
    "Transferable Skills: [Skills to emphasize more]\n",
    "Certification Recommendations: [If applicable]\n",
    "\n",
    "## QUALITY ASSURANCE CHECKLIST\n",
    "Before finalizing, verify:\n",
    "âœ“ All content truthful and based on original CV\n",
    "âœ“ Company research is accurate and recent\n",
    "âœ“ Keywords flow naturally (no stuffing)\n",
    "âœ“ Quantifiable results included where possible\n",
    "âœ“ Industry terminology used appropriately\n",
    "âœ“ ATS compatibility score justified\n",
    "\"\"\"\n",
    "\n",
    "    def optimize_cv(self, cv_text, job_desc, voice_style, industry):\n",
    "        \"\"\"Send prompt to OpenAI and get optimized CV\"\"\"\n",
    "        try:\n",
    "            prompt = self.generate_prompt(cv_text, job_desc, voice_style, industry)\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4\",  # or \"gpt-3.5-turbo\" for lower cost\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert career strategist and ATS optimization specialist.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=3000,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error calling OpenAI API: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"AI CV Optimizer\",\n",
    "        page_icon=\"ðŸ“„\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "    \n",
    "    st.title(\"ðŸš€ AI-Powered CV & Cover Letter Optimizer\")\n",
    "    st.markdown(\"Transform your CV into an ATS-friendly, interview-winning document!\")\n",
    "    \n",
    "    # Sidebar for configuration\n",
    "    with st.sidebar:\n",
    "        st.header(\"âš™ï¸ Configuration\")\n",
    "        \n",
    "        # OpenAI API Key\n",
    "        api_key = st.text_input(\"OpenAI API Key\", type=\"password\", help=\"Get your API key from https://platform.openai.com/api-keys\")\n",
    "        \n",
    "        if not api_key:\n",
    "            st.warning(\"Please enter your OpenAI API key to continue.\")\n",
    "            st.stop()\n",
    "        \n",
    "        # Voice style selection\n",
    "        voice_style = st.selectbox(\n",
    "            \"Voice Style\",\n",
    "            [\"Confident\", \"Formal\", \"Friendly\"],\n",
    "            help=\"Choose the tone for your application materials\"\n",
    "        )\n",
    "        \n",
    "        # Industry selection\n",
    "        industry = st.selectbox(\n",
    "            \"Industry\",\n",
    "            [\"Data\", \"Tech\", \"Marketing\", \"UX\", \"Finance\", \"Healthcare\", \"Consulting\"],\n",
    "            help=\"Select your target industry for optimized content\"\n",
    "        )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = CVOptimizer(api_key)\n",
    "    \n",
    "    # Main content area\n",
    "    col1, col2 = st.columns([1, 1])\n",
    "    \n",
    "    with col1:\n",
    "        st.header(\"ðŸ“„ Upload Your CV\")\n",
    "        \n",
    "        # CV upload\n",
    "        cv_file = st.file_uploader(\n",
    "            \"Choose your CV file\",\n",
    "            type=['pdf', 'docx', 'txt'],\n",
    "            help=\"Upload your current CV in PDF, DOCX, or TXT format\"\n",
    "        )\n",
    "        \n",
    "        cv_text = \"\"\n",
    "        if cv_file is not None:\n",
    "            if cv_file.type == \"application/pdf\":\n",
    "                cv_text = optimizer.extract_text_from_pdf(cv_file)\n",
    "            elif cv_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "                cv_text = optimizer.extract_text_from_docx(cv_file)\n",
    "            else:  # txt file\n",
    "                cv_text = str(cv_file.read(), \"utf-8\")\n",
    "            \n",
    "            st.success(f\"âœ… CV uploaded successfully! ({len(cv_text)} characters)\")\n",
    "            \n",
    "            # Show preview\n",
    "            with st.expander(\"ðŸ“– CV Preview\"):\n",
    "                st.text_area(\"Current CV Content\", cv_text, height=200, disabled=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.header(\"ðŸ’¼ Job Description\")\n",
    "        \n",
    "        job_desc = st.text_area(\n",
    "            \"Paste the job description here\",\n",
    "            height=300,\n",
    "            help=\"Copy and paste the full job description from the job posting\"\n",
    "        )\n",
    "        \n",
    "        if job_desc:\n",
    "            # Extract and show company name\n",
    "            company_name = optimizer.extract_company_name(job_desc)\n",
    "            if company_name:\n",
    "                st.info(f\"ðŸ¢ Detected Company: **{company_name}**\")\n",
    "            \n",
    "            # Extract and show keywords\n",
    "            keywords = optimizer.extract_keywords(job_desc)\n",
    "            if keywords:\n",
    "                with st.expander(\"ðŸŽ¯ Extracted Keywords\"):\n",
    "                    st.write(\", \".join(keywords[:10]) + \"...\" if len(keywords) > 10 else \", \".join(keywords))\n",
    "    \n",
    "    # Optimization button\n",
    "    if st.button(\"ðŸš€ Optimize CV & Generate Cover Letter\", type=\"primary\"):\n",
    "        if not cv_text:\n",
    "            st.error(\"Please upload your CV first!\")\n",
    "        elif not job_desc:\n",
    "            st.error(\"Please enter the job description!\")\n",
    "        else:\n",
    "            with st.spinner(\"ðŸ¤– AI is optimizing your application materials...\"):\n",
    "                result = optimizer.optimize_cv(cv_text, job_desc, voice_style, industry)\n",
    "                \n",
    "                if result:\n",
    "                    st.success(\"âœ… Optimization completed!\")\n",
    "                    \n",
    "                    # Display results in tabs\n",
    "                    tabs = st.tabs([\"ðŸ“Š ATS Score\", \"ðŸ“„ Optimized CV\", \"ðŸ’Œ Cover Letter\", \"ðŸ“ˆ Analytics\", \"ðŸŽ¯ Skills Gap\"])\n",
    "                    \n",
    "                    # Parse the result sections\n",
    "                    sections = {}\n",
    "                    current_section = None\n",
    "                    current_content = []\n",
    "                    \n",
    "                    for line in result.split('\\n'):\n",
    "                        if line.startswith('**[') and line.endswith(']**'):\n",
    "                            if current_section:\n",
    "                                sections[current_section] = '\\n'.join(current_content)\n",
    "                            current_section = line.strip('**[]')\n",
    "                            current_content = []\n",
    "                        else:\n",
    "                            current_content.append(line)\n",
    "                    \n",
    "                    if current_section:\n",
    "                        sections[current_section] = '\\n'.join(current_content)\n",
    "                    \n",
    "                    # Display in tabs\n",
    "                    with tabs[0]:\n",
    "                        if 'ATS_COMPATIBILITY_SCORE' in sections:\n",
    "                            st.markdown(\"### ðŸŽ¯ ATS Compatibility Analysis\")\n",
    "                            st.markdown(sections['ATS_COMPATIBILITY_SCORE'])\n",
    "                    \n",
    "                    with tabs[1]:\n",
    "                        if 'OPTIMIZED_CV' in sections:\n",
    "                            st.markdown(\"### ðŸ“„ Your Optimized CV\")\n",
    "                            st.markdown(sections['OPTIMIZED_CV'])\n",
    "                            \n",
    "                            # Download button\n",
    "                            st.download_button(\n",
    "                                label=\"ðŸ“¥ Download Optimized CV\",\n",
    "                                data=sections['OPTIMIZED_CV'],\n",
    "                                file_name=\"optimized_cv.txt\",\n",
    "                                mime=\"text/plain\"\n",
    "                            )\n",
    "                    \n",
    "                    with tabs[2]:\n",
    "                        if 'COVER_LETTER' in sections:\n",
    "                            st.markdown(\"### ðŸ’Œ Your Tailored Cover Letter\")\n",
    "                            st.markdown(sections['COVER_LETTER'])\n",
    "                            \n",
    "                            # Download button\n",
    "                            st.download_button(\n",
    "                                label=\"ðŸ“¥ Download Cover Letter\",\n",
    "                                data=sections['COVER_LETTER'],\n",
    "                                file_name=\"cover_letter.txt\",\n",
    "                                mime=\"text/plain\"\n",
    "                            )\n",
    "                    \n",
    "                    with tabs[3]:\n",
    "                        if 'KEYWORD_OPTIMIZATION_REPORT' in sections:\n",
    "                            st.markdown(\"### ðŸ“ˆ Keyword Optimization Report\")\n",
    "                            st.markdown(sections['KEYWORD_OPTIMIZATION_REPORT'])\n",
    "                    \n",
    "                    with tabs[4]:\n",
    "                        if 'SKILLS_GAP_ANALYSIS' in sections:\n",
    "                            st.markdown(\"### ðŸŽ¯ Skills Gap Analysis\")\n",
    "                            st.markdown(sections['SKILLS_GAP_ANALYSIS'])\n",
    "                \n",
    "                else:\n",
    "                    st.error(\"Failed to optimize CV. Please check your API key and try again.\")\n",
    "\n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"ðŸ’¡ **Pro Tip**: Always review and customize the generated content before applying!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb297bc9-f22e-4e5c-8af6-c105cc9b52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: openai in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (1.57.0)\n",
      "Requirement already satisfied: requests in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: click in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn openai requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad85f19-4a69-44c6-ac80-55b87374d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c297a0f1-3e46-408d-9c61-f677c0811eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docxNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lxml (from docx)\n",
      "  Downloading lxml-6.0.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: Pillow>=2.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from docx) (11.0.0)\n",
      "Downloading lxml-6.0.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 40.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: docx\n",
      "  Building wheel for docx (setup.py): started\n",
      "  Building wheel for docx (setup.py): finished with status 'done'\n",
      "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53899 sha256=53f313ca1250c8ee3b3d46ea6c7acab17185875715a4901c5a423205097f73a2\n",
      "  Stored in directory: c:\\users\\antho\\appdata\\local\\pip\\cache\\wheels\\c1\\3e\\c3\\e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
      "Successfully built docx\n",
      "Installing collected packages: lxml, docx\n",
      "Successfully installed docx-0.2.4 lxml-6.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178cfc5e-8300-4df9-8941-e536092c31e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (1.57.0)\n",
      "Requirement already satisfied: requests in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f629fed-3e19-4a36-8cc7-d3ed0ce61b56",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3241024564.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install requests\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd1f5fca-fa02-492a-841c-cc91e8ac6031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17f4faa-0237-4717-9971-b0f917e47043",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3987540286.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip uninstall docx\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Uninstall the conflicting package\n",
    "pip uninstall docx\n",
    "\n",
    "# Step 2: Uninstall python-docx\n",
    "pip uninstall python-docx\n",
    "\n",
    "# Step 3: Reinstall the correct python-docx package\n",
    "pip install python-docx\n",
    "\n",
    "# Step 4: Verify it works\n",
    "python -c \"from docx import Document; print('âœ… python-docx working!')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117b070c-2290-41ef-9532-af1a03f65385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c878b41c-a4b5-479a-9672-876a2a61aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from python-docx) (6.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\antho\\anaconda3\\envs\\llms\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "af792e8d-3cd8-46cb-93df-215c032f37ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
